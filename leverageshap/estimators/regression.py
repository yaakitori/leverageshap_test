import numpy as np
import scipy
import scipy.special
import math

# ã€Œãƒã‚¹ã‚¯è¡Œåˆ— ğ‘ ã®å„è¡Œï¼ˆã©ã®ç‰¹å¾´é‡ã‚’ 1 ã«ã™ã‚‹ã‹ï¼‰ã€ ã‚’ä½œã‚‹åœŸå°ãŒ combination_generator
def ith_combination(pool: range, r: int, index: int):
    # Function written by ChatGPT
    """
    pool ã®è¦ç´ ã‹ã‚‰ã¡ã‚‡ã†ã© r å€‹ã‚’ è¾æ›¸é †ã§é¸ã¶ã¨ãã€
    â€œindex ç•ªç›®â€ ã®çµ„åˆã›ã®ã¿ã‚’ç›´æ¥è¨ˆç®—ã™ã‚‹é–¢æ•°ã€‚å…¨çµ„åˆã›ã‚’åˆ—æŒ™ã›ãšã«é«˜é€Ÿã«å–å¾—ã§ãã‚‹ã€‚
    ã™ã¹ã¦ã®çµ„åˆã›ã‚’åˆ—æŒ™ã—ã¦ã‹ã‚‰å–ã‚Šå‡ºã™ã¨ãƒ¡ãƒ¢ãƒªã¨æ™‚é–“ãŒã‹ã‹ã‚‹ã®ã§ã€è¨ˆæ•°ï¼ˆcombinatorial countingï¼‰ã‚’ä½¿ã£ã¦ä¸€ç™ºã§æ±‚ã‚ã‚‹

    Args:
        pool (range): è¦ç´ ã‚’é¸ã¶å…ƒã®é›†åˆ
        r (int): é¸æŠã™ã‚‹è¦ç´ ã®æ•°ï¼ˆç‰¹å¾´é‡ã®éƒ¨åˆ†é›†åˆã®ã‚µã‚¤ã‚ºï¼‰
        index (int): å–å¾—ã—ãŸã„çµ„åˆã›ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹

    Returns:
        tuple: index ç•ªç›®ã®çµ„åˆã›ã‚’ã‚¿ãƒ—ãƒ«ã§è¿”ã™
    """
    n = len(pool)
    combination = []
    elements_left = n
    k = r
    start = 0
    
    for i in range(r): # rå€‹ã®ç‰¹é•·é‡ï¼ˆè¦ç´ ï¼‰ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        # Find the largest value for the first element in the combination
        # that allows completing the remaining k-1 elements
        for j in range(start, elements_left):
            count = math.comb(elements_left - j - 1, k - 1)
            if index < count:
                combination.append(pool[j])
                k -= 1
                start = j + 1
                break
            index -= count
    
    return tuple(combination)

## å„éƒ¨åˆ†é›†åˆã®ã‚µã‚¤ã‚ºã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã¨ ãã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã•ã‚ŒãŸã‚µã‚¤ã‚ºã®éƒ¨åˆ†é›†åˆã‚’ç”Ÿæˆ ##
def combination_generator(gen, n, s, num_samples):
    """
        Generate num_samples random combinations of s elements from a pool num_samples of size n in two settings:
        1. If the number of combinations is small (converting to an int does NOT cause an overflow error), randomly sample num_samples integers without replacement and generate the corresponding combinations on the fly with ith_combination.
        2. If the number of combinations is large (converting to an int DOES cause an overflow error), randomly sample num_samples combinations directly with replacement.
        Leverage SHAP ã§ã¯ã€Œç‰¹å¾´é‡ ğ‘› å€‹ã‹ã‚‰ã‚µã‚¤ã‚º s ã®éƒ¨åˆ†é›†åˆã‚’ num_samples å€‹ãƒ©ãƒ³ãƒ€ãƒ ã«å–ã‚‹ã€ã¨ã„ã†æ“ä½œã‚’é »ç¹ã«è¡Œã†ã€‚
        ã“ã®é–¢æ•°ã¯ãã®éƒ¨åˆ†é›†åˆã‚’ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã¨ã—ã¦é †æ¬¡è¿”ã™
        Args:
            gen (np.random.Generator): numpy ã® random generator
            n (int): ç‰¹å¾´é‡æ•°
            s (int): éƒ¨åˆ†é›†åˆã®ã‚µã‚¤ã‚º
            num_samples (int): ç”Ÿæˆã™ã‚‹éƒ¨åˆ†é›†åˆã®æ•°
    """
    num_combos = math.comb(n, s)
    try:
        indices = gen.choice(num_combos, num_samples, replace=False)  # 0 ~ num_combos-1 ã®æ•´æ•°ã®ä¸­ã‹ã‚‰ã€num_sampleå€‹ã®æ•´æ•°ã‚’é‡è¤‡ãªã—ã§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        for i in indices:
            yield ith_combination(range(n), s, i) # ç‰¹å¾´é‡ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¦ç´ ã«æŒã¤ãƒªã‚¹ãƒˆã‚’å‡ºåŠ›
    except OverflowError:
        for _ in range(num_samples):
            yield gen.choice(n, s, replace=False)  # è¦ç´ ã‚’ç›´æ¥æŠ½å‡ºï¼ˆã“ã¡ã‚‰ã¯ with replacement ã®ã‚ˆã†ãªæŒ¯ã‚‹èˆã„ï¼‰


class RegressionEstimator:
    def __init__(self, model, baseline, explicand, num_samples, paired_sampling=False, leverage_sampling=False, bernoulli_sampling=False):
        self.model = model
        self.baseline = baseline
        self.explicand = explicand # ãã®ã¾ã¾ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆ1ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼‰
        # Subtract 2 for the baseline and explicand and ensure num_samples is even
        self.num_samples = int((num_samples -2 ) // 2) * 2 # å¿…ãšå¶æ•°ã«ã™ã‚‹
        self.paired_sampling = paired_sampling # éƒ¨åˆ†é›†åˆã®è£œé›†åˆã‚‚åˆã‚ã›ã¦ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        self.n = self.baseline.shape[1] # Number of features
        self.gen = np.random.Generator(np.random.PCG64())
        self.sample_weight = lambda s : 1 / (s * (self.n - s)) if not leverage_sampling else np.ones_like(s)
        self.reweight = lambda s : 1 / (self.sample_weight(s) * (s * (self.n - s)))
        self.kernel_weights = [] # é‡ã¿ã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆã€å‡ºåŠ›ã•ã›ãŸã„
        self.sample = self.sample_with_replacement if not bernoulli_sampling else self.sample_without_replacement
        #self.used_indices = set()
    
    def add_one_sample(self, idx, indices, weight):
        """ç‰¹å¾´é‡ã®çµ„ã¿åˆã‚ã›ã‚’ä½œæˆã—ã€é‡ã¿ã‚‚è¿½åŠ """
        #indices = sorted(indices)
        #if tuple(indices) in self.used_indices: return
        #self.used_indices.add(tuple(indices))
        if not self.paired_sampling:
            self.SZ_binary[idx, indices] = 1
            self.kernel_weights.append(weight)
        else:
            indices_complement = np.array([i for i in range(self.n) if i not in indices]) # è£œé›†åˆ
            self.SZ_binary[2*idx, indices] = 1
            self.kernel_weights.append(weight)
            self.SZ_binary[2*idx+1, indices_complement] = 1 # è£œé›†åˆ
            self.kernel_weights.append(weight)

    
    def sample_with_replacement(self):
        self.SZ_binary = np.zeros((self.num_samples, self.n))
        valid_sizes = np.array(list(range(1, self.n)))
        prob_sizes = self.sample_weight(valid_sizes) # ã‚µã‚¤ã‚ºã«å¿œã˜ã¦é‡ã¿ã¥ã‘ï¼ˆleverage_sampling=Falseãªã‚‰ï¼‰
        prob_sizes = prob_sizes / np.sum(prob_sizes)
        num_sizes = self.num_samples if not self.paired_sampling else self.num_samples // 2 # paired_samplingã¯åŠåˆ†ã«ã™ã‚‹
        sampled_sizes = self.gen.choice(valid_sizes, num_sizes, p=prob_sizes) # å„ã‚µã‚¤ã‚ºã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹æ•°ã‚’æ±ºå®š
        for idx, s in enumerate(sampled_sizes):
            indices = self.gen.choice(self.n, s, replace=False) # 1ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‹ã‚‰så€‹ã®ç‰¹å¾´é‡ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆé‡è¤‡ãªã—ï¼‰
            # weight = Pr(sampling this set) * w(s)
            weight = 1 / (self.sample_weight(s) * s * (self.n - s))
            self.add_one_sample(idx, indices, weight=weight)
    
    def find_constant_for_bernoulli(self, max_C = 1e10):
        """Leverage SHAP ã® â€œå…¨2**ğ‘›âˆ’2å€‹ã‚ã‚‹éƒ¨åˆ†é›†åˆ S ã‚’ Bernoulli æŠ½é¸ã§å–ã‚‹â€ã¨ã„ã†ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ‰‹æ³•ï¼ˆwithout-replacement ç‰ˆï¼‰
        Bernoulli Sampling ã®ã‚ªãƒ¼ãƒãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å®šæ•° C ã‚’äºŒåˆ†æ¢ç´¢ã§æ±ºå®šã™ã‚‹ã€‚
        ç›®çš„ï¼šå„éƒ¨åˆ†é›†åˆã‚µã‚¤ã‚º s ã«å¯¾ã—ã¦ p_s = min(1, 2*C*weight(s)/binom(self.n, s) ) ã¨ã„ã†ç¢ºç‡ã‚’ã‹ã‘ã¦ã€Œå–ã‚‹/å–ã‚‰ãªã„ã€ã‚’æ±ºã‚ã‚‹ã€‚
        ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ãŸã¨ãã®ã‚µãƒ³ãƒ—ãƒ«æ•°ã®æœŸå¾…å€¤ãŒ m ã«ãªã‚‹ã‚ˆã†ã« C ã‚’æ¢ã™ã€‚

        Args:
            max_C (_type_, optional): _description_. Defaults to 1e10.

        Returns:
            _type_: _description_
        """
        # Choose C so that sampling without replacement from min(1, C*prob) gives the same expected number of samples
        C = 1 # Assume at least n - 1 samples
        m = min(self.num_samples, 2**self.n-2) # Maximum number of samples is 2^n -2
        def expected_samples(C):
            """å®šæ•° C ã®ã¨ãã«å¾—ã‚‰ã‚Œã‚‹ã‚µãƒ³ãƒ—ãƒ«æ•°ã®æœŸå¾…å€¤ã‚’è¿”ã™ã€‚"""
            # scipy.special.binom(self.n, s) is the number of combinations of n choose s
            expected = [min(scipy.special.binom(self.n, s), 2* C * self.sample_weight(s)) for s in range(1, self.n)]
            #print(f'Expected samples: {np.sum(expected)}')
            #print(f'Constraint: {m}')
            #print(f'C: {C}')
            return np.sum(expected)
        # Efficiently find C with äºŒåˆ†æ¢ç´¢
        L = 1
        R = scipy.special.binom(self.n, self.n // 2) * self.n ** 2
        while round(expected_samples(C)) != m: # æœŸå¾…å€¤ãŒãƒ”ãƒƒã‚¿ãƒª m ã«ãªã‚‹ã¾ã§ãƒ«ãƒ¼ãƒ—
            if expected_samples(C) < m:
                L = C  # æœŸå¾…å€¤ãŒå°ã•ã‘ã‚Œã° C ã‚’å¤§ããã™ã‚‹
            else:
                R = C # æœŸå¾…å€¤ãŒå¤§ãã‘ã‚Œã° C ã‚’å°ã•ãã™ã‚‹
            C = (L + R) / 2
        self.C = round(C)
    
    def sample_without_replacement(self):
        """
        ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° without replacementï¼ˆç½®æ›ãªã—ï¼‰ã‚’å®Ÿè¡Œã—ã€
        self.SZ_binary ã«äºŒå€¤ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ï¼ˆã©ã®ç‰¹å¾´é‡ã‚’
        ON ã«ã—ãŸã‹ï¼‰ã¨å¯¾å¿œã™ã‚‹é‡ã¿ã‚’æ ¼ç´ã™ã‚‹ã€‚
        """
        self.find_constant_for_bernoulli() # ã‚ªãƒ¼ãƒãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å®šæ•° C ã‚’æ±ºå®šã™ã‚‹

        # å„éƒ¨åˆ†é›†åˆã‚µã‚¤ã‚º s=1â€¦n-1 ã«ã¤ã„ã¦ã€å®Ÿéš›ã«ä½•å€‹ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹ã‹ã‚’æ±ºå®š
        m_s_all = []
        for s in range(1, self.n):
            # Sample from Binomial distribution with (n choose s) trials and probability min(1, C*sample_weight(s) / (n choose s))
            prob = min(1, 2*self.C * self.sample_weight(s) / scipy.special.binom(self.n, s))  # Bernoulli ã®æˆåŠŸç¢ºç‡
            try:
                m_s = self.gen.binomial(int(scipy.special.binom(self.n, s)), prob)  # äºŒé …åˆ†å¸ƒ(ãƒ™ãƒ«ãƒŒãƒ¼ã‚¤è©¦è¡Œã‚’ãŸãã•ã‚“ç¹°ã‚Šè¿”ã—ãŸã¨ãã«ã€ã€ŒæˆåŠŸã€ãŒä½•å›èµ·ãã‚‹ã‹)ã§ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’å¾—ã‚‹
            except OverflowError:  # If the number of samples is too large, assume the number of samples is the expected number
                m_s = int(prob * scipy.special.binom(self.n, s)) # æœŸå¾…å€¤ã‚’ä½¿ã†
            if self.paired_sampling:
                if s == self.n // 2: # ä¸­å¤®ã‚µã‚¤ã‚ºã«åˆ°é”ã—ãŸã‚‰ã€è£œé›†åˆã‚’å«ã‚ã‚‹ã¨ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãŒçµ‚äº†ã—ã¦ã„ã‚‹
                    if self.n % 2 == 0: # Special handling for middle set size if n is even
                        # n ãŒå¶æ•°ã‹ã¤ä¸­å¤®ã‚µã‚¤ã‚ºãªã‚‰ã€é‡è¤‡ã—ã¦ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ãªã„ã‚ˆã†åŠåˆ†ã«
                        m_s_all.append(m_s // 2)
                    else:
                        m_s_all.append(m_s)
                    break
            m_s_all.append(m_s)
        sampled_m = np.sum(m_s_all)
        num_rows = sampled_m if not self.paired_sampling else sampled_m * 2
        self.SZ_binary = np.zeros((num_rows, self.n))  # self.SZ_binaryï¼šGNNShapã®mask_matrixã«å½“ãŸã‚‹ã®ã§ã€å‡ºåŠ›ã—ãŸã„
        idx = 0
        for s, m_s in enumerate(m_s_all):
            """
            å„éƒ¨åˆ†é›†åˆã‚µã‚¤ã‚ºsã«ã¤ã„ã¦ã€äº‹å‰ã«æ±ºã‚ãŸã‚µãƒ³ãƒ—ãƒ«æ•°ğ‘š_såˆ†ã ã‘ã€combination_generator ã§ã€Œã©ã®ç‰¹å¾´é‡ã‚’é¸ã¶ã‹ã€ã®çµ„åˆã›ã‚’ç”Ÿæˆã—ã€
            ãã®çµ„åˆã›ã‚’äºŒå€¤ãƒã‚¹ã‚¯ï¼ˆself.SZ_binary ã®è¡Œï¼‰ã¨ã—ã¦æ ¼ç´ã€‚ã‹ã¤ã€å¯¾å¿œã™ã‚‹é‡ã¿ weight ã‚’ add_one_sample ã§è¨­å®š
            """
            s += 1
            prob = min(1, 2*self.C * self.sample_weight(s) / scipy.special.binom(self.n, s)) # è«–æ–‡ä¸­ã®ãƒ™ãƒ«ãƒŒãƒ¼ã‚¤åˆ†å¸ƒã®å¼
            weight = 1 / (prob * scipy.special.binom(self.n, s) * (self.n - s) * s ) # Shapã®è¨ˆç®—ã«ä½¿ã†é‡ã¿
            if self.paired_sampling and s == self.n // 2 and self.n % 2 == 0: # ãƒšã‚¢ä»˜ãã‹ã¤ä¸­å¤®ã‚µã‚¤ã‚ºã®æ™‚
                # n-1 å€‹ã‹ã‚‰ (s-1) å€‹ã‚’é¸ã¶çµ„åˆã›ã‚’ç”Ÿæˆã—ã€æœ€å¾Œã«è¦ç´  n-1 ã‚’è¿½åŠ 
                combo_gen = combination_generator(self.gen, self.n - 1, s-1, m_s)
                for indices in combo_gen:
                    # indices = ç‰¹å¾´é‡ã®çµ„ã¿åˆã‚ã›
                    self.add_one_sample(idx, list(indices) + [self.n-1], weight = weight)
                    idx += 1
            else:
                # é€šå¸¸ã®çµ„åˆã›ç”Ÿæˆï¼š0...n-1 ã‹ã‚‰ s å€‹é¸ã¶
                combo_gen = combination_generator(self.gen, self.n, s, m_s)
                for indices in combo_gen:
                    self.add_one_sample(idx, list(indices), weight = weight)
                    idx += 1

    def compute(self):
        """
        SHAPå€¤ã‚’è¨ˆç®—ã™ã‚‹ã€‚mainé–¢æ•°

        """
        # Sample
        self.sample()
        # A = Z P
        # y = v(z) - v0
        # b = y - Z1 (v1 - v0) / n
        # (A^T S^T S A)^-1 A^T S^T S b + (v1 - v0) / n
        # (P^T Z^T S^T S Z P)^-1 P^T Z^T S^T S b + (v1 - v0) / n

        # Remove zero rows
        SZ_binary = self.SZ_binary[np.sum(self.SZ_binary, axis=1) != 0]
        # åŸºæº–å€¤ v0 ã¨å¯¾è±¡å€¤ v1 ã‚’ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰äºˆæ¸¬
        # baseline: ã™ã¹ã¦ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã§å„ç‰¹å¾´é‡ã§ã®å¹³å‡å€¤ã®ç‰¹å¾´é‡å…¥åŠ›
        # explicand: èª¬æ˜å¯¾è±¡ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãã®ã¾ã¾ã®ç‰¹å¾´é‡å…¥åŠ›
        v0, v1 = self.model.predict(self.baseline), self.model.predict(self.explicand)
        # mask ãŒ1ãªã‚‰ explicand ã®ç‰¹å¾´é‡ã€0ãªã‚‰ baseline ã®ç‰¹å¾´é‡ã‚’é¸ã¶
        inputs = self.baseline * (1 - SZ_binary) + self.explicand * SZ_binary
        Sy = self.model.predict(inputs) - v0
        SZ_binary1 = np.sum(SZ_binary, axis=1)

        Sb = Sy - (v1 - v0) * SZ_binary1 / self.n

        # Projection matrix
        P = np.eye(self.n) - 1/self.n * np.ones((self.n, self.n))

        PZSSb = P @ SZ_binary.T @ np.diag(self.kernel_weights) @ Sb
        PZSSZP = P @ SZ_binary.T @ np.diag(self.kernel_weights) @ SZ_binary @ P
        PZSSZP_inv_PZSSb = np.linalg.lstsq(PZSSZP, PZSSb, rcond=None)[0]

        self.phi = PZSSZP_inv_PZSSb + (v1 - v0) / self.n

        return self.phi

# TODO
def leverage_shap(baseline, explicand, model, num_samples):
    estimator = RegressionEstimator(model, baseline, explicand, num_samples, paired_sampling=True, leverage_sampling=True, bernoulli_sampling=True)
    return estimator.compute()

def leverage_shap_wo_bernoulli(baseline, explicand, model, num_samples):
    estimator = RegressionEstimator(model, baseline, explicand, num_samples, paired_sampling=True, leverage_sampling=True, bernoulli_sampling=False)
    return estimator.compute()

def leverage_shap_wo_bernoulli_paired(baseline, explicand, model, num_samples):
    estimator = RegressionEstimator(model, baseline, explicand, num_samples, paired_sampling=False, leverage_sampling=True, bernoulli_sampling=False)
    return estimator.compute()

def kernel_shap_paired(baseline, explicand, model, num_samples):
    estimator = RegressionEstimator(model, baseline, explicand, num_samples, paired_sampling=True, leverage_sampling=False, bernoulli_sampling=False)
    return estimator.compute() 

def kernel_shap(baseline, explicand, model, num_samples):
    estimator = RegressionEstimator(model, baseline, explicand, num_samples, paired_sampling=False, leverage_sampling=False, bernoulli_sampling=False)
    return estimator.compute()

def leverage_shap_wo_paired(baseline, explicand, model, num_samples):
    estimator = RegressionEstimator(model, baseline, explicand, num_samples, paired_sampling=False, leverage_sampling=True, bernoulli_sampling=False)
    return estimator.compute()